experiment:
  # The name of the experiment to use during training or model validation in staging deployment target.
  # TODO: This value must be the same as experiment_name defined in
  # databricks_mlops_stacks/databricks.yml for staging deployment target.
  name: /staging-databricks-mlops-stacks-experiment

# Set the registry server URI. This property is especially useful if you have a registry
# server thatâ€™s different from the tracking server.
model_registry:
  # The MLflow registered model name under which to register model versions
  # This value must be the same as model_name defined in
  # databricks_mlops_stacks/databricks.yml for staging deployment target.
  model_name: staging-databricks-mlops-stacks-model

# Override the default train / validation / test dataset split ratios
SPLIT_RATIOS: [0.75, 0.125, 0.125]

INGEST_CONFIG:
  # For different options please read: https://github.com/mlflow/recipes-regression-template#ingest-step
  # TODO: Specify the format of the dataset
  using: spark_sql
  # TODO: update this field to point to the path to your model training dataset on your staging Databricks workspace,
  # to be used in the staging instance of your ML jobs. For example, you may want to create a downsampled version of your
  # full production dataset and specify its path here.
  sql: SELECT * FROM delta.`dbfs:/databricks-datasets/nyctaxi-with-zipcodes/subsampled`
  loader_method: load_file_as_dataframe

INGEST_SCORING_CONFIG:
  # For different options please read: https://github.com/mlflow/recipes-regression-template#batch-scoring
  # TODO: Specify the format of the dataset
  using: spark_sql
  # TODO: Specify the name/path of the input table for batch inference in your staging workspace here
  sql: SELECT * FROM delta.`dbfs:/databricks-datasets/nyctaxi-with-zipcodes/subsampled`
  loader_method: load_file_as_dataframe

PREDICT_OUTPUT_CONFIG:
  # For different options please read: https://github.com/mlflow/recipes-regression-template#predict-step
  # Specify the output format of the batch scoring predict step
  using: table
  # TODO: Specify the name of the output table for batch inference in your prod workspace here
  location: "databricks-mlops-stacks_batch_scoring"
